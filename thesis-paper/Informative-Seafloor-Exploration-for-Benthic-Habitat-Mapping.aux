\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{apalike}
\@writefile{toc}{\contentsline {chapter}{Declaration of Authorship}{iii}{dummy.1}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Abstract}{v}{dummy.2}}
\@writefile{toc}{\vspace  {1em}}
\citation{GaussianProcessForMachineLearning}
\citation{GaussianProcessTerrainFigure}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{xi}{dummy.4}}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{xiii}{dummy.6}}
\@writefile{toc}{\contentsline {chapter}{Abbreviations}{xv}{dummy.8}}
\gdef \LT@i {\LT@entry 
    {2}{56.86763pt}\LT@entry 
    {2}{258.90025pt}}
\citation{Niedzielski2013231,Colbo201441}
\citation{Niedzielski2013231}
\citation{NOAA}
\citation{Steinberg2015128}
\citation{AsherBender}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Introduction}{{1}{1}{Introduction}{chapter.11}{}}
\newlabel{Introduction@cref}{{[chapter][1][]1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.12}}
\citation{Rigby:ROB20372}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Objectives}{3}{section.13}}
\citation{IMOS}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Contribution}{4}{section.14}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Nomenclature}{5}{section.15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Naming Conventions}{5}{subsection.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}New Nomenclature}{5}{subsection.17}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Structure}{6}{section.18}}
\citation{AsherBender,Rigby:ROB20372,Krause:2008:NSP:1390681.1390689,Kapoor}
\citation{AsherBender}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{7}{chapter.19}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Background}{{2}{7}{Background}{chapter.19}{}}
\newlabel{Background@cref}{{[chapter][2][]2}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Related Work}{7}{section.20}}
\citation{Rigby:ROB20372}
\citation{Krause:2008:NSP:1390681.1390689}
\citation{AsherBender}
\newlabel{Equation:AsherBenderAcquisitionCriterion}{{2.1}{8}{Related Work}{equation.21}{}}
\newlabel{Equation:AsherBenderAcquisitionCriterion@cref}{{[equation][1][2]2.1}{8}}
\newlabel{Equation:AsherBenderMutualInformationCriterion}{{2.2}{8}{Related Work}{equation.22}{}}
\newlabel{Equation:AsherBenderMutualInformationCriterion@cref}{{[equation][2][2]2.2}{8}}
\newlabel{Equation:KrauseAcquisitionCriterion}{{2.3}{8}{Related Work}{equation.23}{}}
\newlabel{Equation:KrauseAcquisitionCriterion@cref}{{[equation][3][2]2.3}{8}}
\citation{Kapoor}
\citation{Roman:SequentialBayesianOptimisation}
\citation{GaussianProcessForMachineLearning}
\citation{GaussianProcessForMachineLearning}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Gaussian Processes}{10}{section.24}}
\citation{GaussianProcessForMachineLearning}
\citation{GaussianProcessForMachineLearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Bayesian Modeling with Gaussian Processes}{11}{subsection.25}}
\newlabel{Background:GaussianProcesses:BayesianModeling}{{2.2.1}{11}{Bayesian Modeling with Gaussian Processes}{subsection.25}{}}
\newlabel{Background:GaussianProcesses:BayesianModeling@cref}{{[subsection][1][2,2]2.2.1}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Illustration of Gaussian Process Bayesian Modeling: The mean prediction is shown as the solid line. Four samples are drawn in each case, represented by the dashed line. The shared region represents the 2-$\sigma $ bounds of the prediction at each input feature value $x$. Two points are observed which updated the distribution from the prior to the posterior.  Figure (a) shows the situation for the prior distribution.  Figure (b) shows the situation for the posterior distribution.   Source: Rasmussen and Williams (2006) \citep  {GaussianProcessForMachineLearning}\relax }}{12}{figure.caption.28}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Background:OceanEnvironmentModeling:Figure:bayesianmodeling}{{2.1}{12}{Illustration of Gaussian Process Bayesian Modeling: The mean prediction is shown as the solid line. Four samples are drawn in each case, represented by the dashed line. The shared region represents the 2-$\sigma $ bounds of the prediction at each input feature value $x$. Two points are observed which updated the distribution from the prior to the posterior.\\ Figure (a) shows the situation for the prior distribution.\\ Figure (b) shows the situation for the posterior distribution. \\ Source: Rasmussen and Williams (2006) \citep {GaussianProcessForMachineLearning}\relax }{figure.caption.28}{}}
\newlabel{Background:OceanEnvironmentModeling:Figure:bayesianmodeling@cref}{{[figure][1][2]2.1}{12}}
\citation{GaussianProcessForMachineLearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Kernel Functions}{13}{subsection.30}}
\newlabel{Background:GaussianProcesses:KernelFunctions}{{2.2.2}{13}{Kernel Functions}{subsection.30}{}}
\newlabel{Background:GaussianProcesses:KernelFunctions@cref}{{[subsection][2][2,2]2.2.2}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.1}Stationary Kernels}{13}{subsubsection.31}}
\newlabel{Background:GaussianProcess:Equation:SquaredExponentialKernel}{{2.4}{14}{Stationary Kernels}{equation.33}{}}
\newlabel{Background:GaussianProcess:Equation:SquaredExponentialKernel@cref}{{[equation][4][2]2.4}{14}}
\citation{GaussianProcessForMachineLearning}
\newlabel{Background:GaussianProcess:Equation:MaternKernel}{{2.5}{15}{Stationary Kernels}{equation.34}{}}
\newlabel{Background:GaussianProcess:Equation:MaternKernel@cref}{{[equation][5][2]2.5}{15}}
\citation{GaussianProcessTerrainFigure}
\citation{GaussianProcessTerrainFigure}
\citation{AdaptiveNonStationaryKernel}
\newlabel{Background:GaussianProcess:Equation:PracticalMaternKernels}{{2.6}{16}{Stationary Kernels}{equation.35}{}}
\newlabel{Background:GaussianProcess:Equation:PracticalMaternKernels@cref}{{[equation][6][2]2.6}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.2}Non-Stationary Kernels}{16}{subsubsection.36}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Illustration of non-stationary Gaussian process for terrain modeling \citep  {GaussianProcessTerrainFigure}   Flat parts have high length scales (slow varying) while   rough parts have low length scales (fast varying)\relax }}{17}{figure.caption.37}}
\newlabel{Background:GaussianProcess:Figure:gaussianprocesslengthscale}{{2.2}{17}{Illustration of non-stationary Gaussian process for terrain modeling \citep {GaussianProcessTerrainFigure} \\ Flat parts have high length scales (slow varying) while \\ rough parts have low length scales (fast varying)\relax }{figure.caption.37}{}}
\newlabel{Background:GaussianProcess:Figure:gaussianprocesslengthscale@cref}{{[figure][2][2]2.2}{17}}
\newlabel{Background:GaussianProcess:Equation:NonStationaryKernel}{{2.7}{17}{Non-Stationary Kernels}{equation.38}{}}
\newlabel{Background:GaussianProcess:Equation:NonStationaryKernel@cref}{{[equation][7][2]2.7}{17}}
\citation{GaussianProcessForMachineLearning}
\newlabel{Background:GaussianProcess:Equation:NonStationaryKernelToStationary}{{2.8}{18}{Non-Stationary Kernels}{equation.39}{}}
\newlabel{Background:GaussianProcess:Equation:NonStationaryKernelToStationary@cref}{{[equation][8][2]2.8}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Regression}{18}{subsection.40}}
\newlabel{Background:GaussianProcesses:Regression}{{2.2.3}{18}{Regression}{subsection.40}{}}
\newlabel{Background:GaussianProcesses:Regression@cref}{{[subsection][3][2,2]2.2.3}{18}}
\newlabel{Background:GaussianProcess:Equation:Distribution}{{2.9}{19}{Regression}{equation.41}{}}
\newlabel{Background:GaussianProcess:Equation:Distribution@cref}{{[equation][9][2]2.9}{19}}
\newlabel{Background:GaussianProcess:Equation:DataMatrix}{{2.10}{19}{Regression}{equation.42}{}}
\newlabel{Background:GaussianProcess:Equation:DataMatrix@cref}{{[equation][10][2]2.10}{19}}
\newlabel{Background:GaussianProcess:Equation:ConditionalDistribution}{{2.11}{19}{Regression}{equation.44}{}}
\newlabel{Background:GaussianProcess:Equation:ConditionalDistribution@cref}{{[equation][11][2]2.11}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.1}Hyperparameter Learning}{20}{subsubsection.45}}
\newlabel{Background:GaussianProcess:Equation:LogMarginalLikelihood}{{2.12}{20}{Hyperparameter Learning}{equation.46}{}}
\newlabel{Background:GaussianProcess:Equation:LogMarginalLikelihood@cref}{{[equation][12][2]2.12}{20}}
\citation{GaussianProcessForMachineLearning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.2}Sampling from a Gaussian Process}{21}{subsubsection.47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Classification}{21}{subsection.48}}
\newlabel{Background:GaussianProcesses:Classification}{{2.2.4}{21}{Classification}{subsection.48}{}}
\newlabel{Background:GaussianProcesses:Classification@cref}{{[subsection][4][2,2]2.2.4}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.1}Response Functions}{21}{subsubsection.49}}
\newlabel{Background:GaussianProcess:Equation:Logistic}{{2.13}{22}{Response Functions}{equation.50}{}}
\newlabel{Background:GaussianProcess:Equation:Logistic@cref}{{[equation][13][2]2.13}{22}}
\newlabel{Background:GaussianProcess:Equation:normalcdf}{{2.14}{22}{Response Functions}{equation.51}{}}
\newlabel{Background:GaussianProcess:Equation:normalcdf@cref}{{[equation][14][2]2.14}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.2}Binary Classification}{22}{subsubsection.52}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.3}Laplace Approximation}{23}{subsubsection.54}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.4}Probabilistic Least Squares}{23}{subsubsection.55}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.5}Multiclass Classification: One v.s. All}{23}{subsubsection.56}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.6}Multiclass Classification: All v.s. All}{23}{subsubsection.57}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.7}Fusion of Prediction Probability}{23}{subsubsection.58}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.8}Entropy}{24}{subsubsection.59}}
\newlabel{Background:GaussianProcess:Equation:DiscreteEntropy}{{2.15}{24}{Entropy}{equation.60}{}}
\newlabel{Background:GaussianProcess:Equation:DiscreteEntropy@cref}{{[equation][15][2]2.15}{24}}
\newlabel{Background:GaussianProcess:Equation:ContinuousEntropy}{{2.16}{24}{Entropy}{equation.61}{}}
\newlabel{Background:GaussianProcess:Equation:ContinuousEntropy@cref}{{[equation][16][2]2.16}{24}}
\citation{BayesianOptimisation}
\citation{BayesianOptimisation}
\citation{SequentialBayesianOptimisation}
\citation{ParametricPOMDP}
\citation{ParametricPOMDP}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.9}Sampling from a Gaussian Process for Classifiers}{25}{subsubsection.62}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Active Sampling}{25}{section.63}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Static Active Sampling}{25}{subsection.64}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Dynamic Active Sampling}{25}{subsection.65}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Informative Path Planning}{25}{section.66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Myopic and Non-myopic Planning}{26}{subsection.68}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Advantages of Gaussian Process Models}{26}{subsection.69}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Benthic Habitat Mapping}{27}{chapter.70}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Benthic-Habitat-Mapping}{{3}{27}{Benthic Habitat Mapping}{chapter.70}{}}
\newlabel{Benthic-Habitat-Mapping@cref}{{[chapter][3][]3}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Gaussian Process Classifiers for Benthic Habitat Mapping}{27}{section.71}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Benthic Habitat Modeling}{27}{section.72}}
\newlabel{ModelingOceanEnvironment:ModelingFeatures}{{3.2}{27}{Benthic Habitat Modeling}{section.72}{}}
\newlabel{ModelingOceanEnvironment:ModelingFeatures@cref}{{[section][2][3]3.2}{27}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Bathymetric Features\relax }}{28}{table.caption.73}}
\newlabel{Background:OceanEnvironmentModeling:Table:Features}{{3.1}{28}{Bathymetric Features\relax }{table.caption.73}{}}
\newlabel{Background:OceanEnvironmentModeling:Table:Features@cref}{{[table][1][3]3.1}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Environment Modeling\relax }}{29}{figure.caption.74}}
\newlabel{Background:OceanEnvironmentModeling:Figure:modelingprocess}{{3.1}{29}{Environment Modeling\relax }{figure.caption.74}{}}
\newlabel{Background:OceanEnvironmentModeling:Figure:modelingprocess@cref}{{[figure][1][3]3.1}{29}}
\citation{Squidle}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Data Matching}{30}{subsection.75}}
\newlabel{Background:OceanEnvironmentModeling:DataMatching}{{3.2.1}{30}{Data Matching}{subsection.75}{}}
\newlabel{Background:OceanEnvironmentModeling:DataMatching@cref}{{[subsection][1][3,2]3.2.1}{30}}
\citation{CentralDifferenceTable}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Illustration of Bathymetric and Label Data Density\relax }}{31}{figure.caption.76}}
\newlabel{Background:OceanEnvironmentModeling:Figure:illustrationBathymetricAgainstLabels}{{3.2}{31}{Illustration of Bathymetric and Label Data Density\relax }{figure.caption.76}{}}
\newlabel{Background:OceanEnvironmentModeling:Figure:illustrationBathymetricAgainstLabels@cref}{{[figure][2][3]3.2}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Feature Extraction}{31}{subsection.77}}
\newlabel{Background:OceanEnvironmentModeling:FeatureExtraction}{{3.2.2}{31}{Feature Extraction}{subsection.77}{}}
\newlabel{Background:OceanEnvironmentModeling:FeatureExtraction@cref}{{[subsection][2][3,2]3.2.2}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Finite Difference Methods: Central Difference Coefficients   The subscripts $i$ represents \relax }}{32}{figure.caption.78}}
\newlabel{Background:OceanEnvironmentModeling:Figure:centraldifferencecofficients}{{3.3}{32}{Finite Difference Methods: Central Difference Coefficients \\ The subscripts $i$ represents \relax }{figure.caption.78}{}}
\newlabel{Background:OceanEnvironmentModeling:Figure:centraldifferencecofficients@cref}{{[figure][3][3]3.3}{32}}
\citation{StefanWilliams:Rugosity}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}GP Classification with Laplace Approximation}{34}{section.79}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Theory}{34}{subsection.80}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Implementation}{34}{subsection.81}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Results}{34}{subsection.82}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}GP Classification with Probabilistic Least Squares Approximation}{34}{section.83}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Theory}{34}{subsection.84}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Implementation}{34}{subsection.85}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Results}{34}{subsection.86}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Drawing from Gaussian Process Classifiers}{34}{section.87}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Theory}{34}{subsection.88}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Implementation}{34}{subsection.89}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Results}{34}{subsection.90}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Laplace Approximation and Probabilistic Least Squares}{34}{section.91}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}The One Versus All Framework}{35}{section.92}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}The All Versus All Framework}{35}{section.93}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Properties and Performance of OVA and AVA Classifiers}{35}{section.94}}
\@writefile{toc}{\contentsline {section}{\numberline {3.10}Probability Fusion Methods}{35}{section.95}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.1}Normalisation Method}{35}{subsection.96}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.2}Mode Keeping}{35}{subsection.97}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.3}Exclusion}{35}{subsection.98}}
\@writefile{toc}{\contentsline {section}{\numberline {3.11}Mapping Scott Reef Benthic Habitats}{35}{section.99}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11.1}Problems and Solutions to Big Data Analysis}{35}{subsection.100}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11.2}Feature Extraction}{35}{subsection.101}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11.3}Case with 4 Labels}{35}{subsection.102}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11.4}Case with 17 Labels}{35}{subsection.103}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Informative Seafloor Exploration}{37}{chapter.104}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Informative-Seafloor-Exploration}{{4}{37}{Informative Seafloor Exploration}{chapter.104}{}}
\newlabel{Informative-Seafloor-Exploration@cref}{{[chapter][4][]4}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Mutual Information}{37}{section.105}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Monte Carlo Estimated Joint Predictive Information Entropy}{37}{section.106}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Binary Classification}{37}{subsection.107}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Multiclass Classification}{37}{subsection.108}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Linearised Model Differential Entropy}{37}{section.109}}
\citation{ShannonEntropy}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Binary Classification}{38}{subsection.110}}
\newlabel{Section:LinearisedEntropy:Equation:PredictiveGP}{{4.1}{38}{Binary Classification}{equation.111}{}}
\newlabel{Section:LinearisedEntropy:Equation:PredictiveGP@cref}{{[equation][1][4]4.1}{38}}
\newlabel{Section:LinearisedEntropy:Equation:PredictiveGaussianDistribution}{{4.2}{38}{Binary Classification}{equation.112}{}}
\newlabel{Section:LinearisedEntropy:Equation:PredictiveGaussianDistribution@cref}{{[equation][2][4]4.2}{38}}
\newlabel{Section:LinearisedEntropy:Equation:Response}{{4.3}{38}{Binary Classification}{equation.113}{}}
\newlabel{Section:LinearisedEntropy:Equation:Response@cref}{{[equation][3][4]4.3}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Linearisation accuracy for a probit response: Green shade represents the latent variance while blue shade represents the predictive variance. Gold lines show local linearisation about latent expectance.\relax }}{39}{figure.caption.114}}
\newlabel{Figure:Linearisation}{{4.1}{39}{Linearisation accuracy for a probit response: Green shade represents the latent variance while blue shade represents the predictive variance. Gold lines show local linearisation about latent expectance.\relax }{figure.caption.114}{}}
\newlabel{Figure:Linearisation@cref}{{[figure][1][4]4.1}{39}}
\citation{GaussianProcessForMachineLearning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1.1}Derivation}{40}{subsubsection.115}}
\newlabel{Section:LinearisedEntropy:Equation:LinearisingSigmoid}{{4.4}{40}{Derivation}{equation.116}{}}
\newlabel{Section:LinearisedEntropy:Equation:LinearisingSigmoid@cref}{{[equation][4][4]4.4}{40}}
\newlabel{Section:LinearisedEntropy:Equation:MomentsLinearisedSigmoid}{{{4.5}}{40}{Derivation}{AMS.118}{}}
\newlabel{Section:LinearisedEntropy:Equation:MomentsLinearisedSigmoid@cref}{{[equation][2147483647][]{4.5}}{40}}
\newlabel{Section:LinearisedEntropy:Equation:BinaryLinearisedEntropy}{{4.6}{40}{Derivation}{equation.119}{}}
\newlabel{Section:LinearisedEntropy:Equation:BinaryLinearisedEntropy@cref}{{[equation][6][4]4.6}{40}}
\citation{GaussianProcessForMachineLearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Multiclass Classification}{41}{subsection.120}}
\newlabel{Section:LinearisedEntropy:Equation:Softmax}{{4.7}{41}{Multiclass Classification}{equation.121}{}}
\newlabel{Section:LinearisedEntropy:Equation:Softmax@cref}{{[equation][7][4]4.7}{41}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2.1}Derivation}{41}{subsubsection.122}}
\newlabel{Section:LinearisedEntropy:Equation:SoftmaxGradient}{{4.8}{41}{Derivation}{equation.123}{}}
\newlabel{Section:LinearisedEntropy:Equation:SoftmaxGradient@cref}{{[equation][8][4]4.8}{41}}
\newlabel{Section:LinearisedEntropy:Equation:SoftmaxGradientVector}{{4.9}{42}{Derivation}{equation.124}{}}
\newlabel{Section:LinearisedEntropy:Equation:SoftmaxGradientVector@cref}{{[equation][9][4]4.9}{42}}
\newlabel{Section:LinearisedEntropy:Equation:LinearisedSoftmax}{{4.10}{42}{Derivation}{equation.125}{}}
\newlabel{Section:LinearisedEntropy:Equation:LinearisedSoftmax@cref}{{[equation][10][4]4.10}{42}}
\newlabel{Section:LinearisedEntropy:Equation:Definitions}{{4.11}{42}{Derivation}{equation.126}{}}
\newlabel{Section:LinearisedEntropy:Equation:Definitions@cref}{{[equation][11][4]4.11}{42}}
\newlabel{Section:LinearisedEntropy:Equation:MomentsLinearisedSoftmax}{{{4.12}}{42}{Derivation}{AMS.128}{}}
\newlabel{Section:LinearisedEntropy:Equation:MomentsLinearisedSoftmax@cref}{{[equation][2147483647][]{4.12}}{42}}
\citation{AsherBender}
\newlabel{Section:LinearisedEntropy:Equation:MulticlassLinearisedEntropy}{{4.13}{43}{Derivation}{equation.129}{}}
\newlabel{Section:LinearisedEntropy:Equation:MulticlassLinearisedEntropy@cref}{{[equation][13][4]4.13}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Interpretation of Model Differential Entropy}{43}{subsection.130}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces GP binary classifier: prediction information entropy and linearised differential entropy under abundant data\relax }}{44}{figure.caption.131}}
\newlabel{Figure:Results:BinaryLinearisedEntropy}{{4.2}{44}{GP binary classifier: prediction information entropy and linearised differential entropy under abundant data\relax }{figure.caption.131}{}}
\newlabel{Figure:Results:BinaryLinearisedEntropy@cref}{{[figure][2][4]4.2}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}The Receding Horizon Formulation}{45}{section.133}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces GP multiclass classifier: prediction information entropy and linearised differential entropy under abundant data\relax }}{46}{figure.caption.132}}
\newlabel{Figure:Results:MulticlassLinearisedEntropy}{{4.3}{46}{GP multiclass classifier: prediction information entropy and linearised differential entropy under abundant data\relax }{figure.caption.132}{}}
\newlabel{Figure:Results:MulticlassLinearisedEntropy@cref}{{[figure][3][4]4.3}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Scott Reef Bathymetric Features\relax }}{46}{figure.caption.134}}
\newlabel{Figure:Results:ScottReefBathymetricFeatures}{{4.4}{46}{Scott Reef Bathymetric Features\relax }{figure.caption.134}{}}
\newlabel{Figure:Results:ScottReefBathymetricFeatures@cref}{{[figure][4][4]4.4}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Formulation and Structure}{46}{subsection.135}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Basic Receding Horizon Structure\relax }}{47}{figure.caption.136}}
\newlabel{Figure:Results:RecedingHorizonMethodOutline}{{4.5}{47}{Basic Receding Horizon Structure\relax }{figure.caption.136}{}}
\newlabel{Figure:Results:RecedingHorizonMethodOutline@cref}{{[figure][5][4]4.5}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Implementation}{47}{subsection.137}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Computational Aspects: Optimisation Process and Bottlenecks}{48}{subsection.138}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Computational Aspects: Model Update}{48}{subsection.139}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Informative Exploration over Scott Reef Seafloor}{48}{section.140}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Ground Truth Generation}{48}{subsection.141}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Practical Considerations}{48}{subsection.142}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Entropy and Prediction Maps}{48}{subsection.143}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Performance Assessment}{48}{subsection.144}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion and Future Work}{49}{chapter.145}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Conclusion}{{5}{49}{Conclusion and Future Work}{chapter.145}{}}
\newlabel{Conclusion@cref}{{[chapter][5][]5}{49}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Computational Aspects of Gaussian Processes}{51}{appendix.146}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Appendix:ComputationalAspectsGaussianProcesses}{{A}{51}{Computational Aspects of Gaussian Processes}{appendix.146}{}}
\newlabel{Appendix:ComputationalAspectsGaussianProcesses@cref}{{[appendix][1][2147483647]A}{51}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Numerical Stability}{51}{section.147}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Cholesky Decomposition}{51}{subsection.148}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Solving Triangular Matrix Equations}{51}{subsection.149}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.3}Cholesky Jittering}{51}{subsection.150}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Time Complexity}{51}{section.151}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Numpy and Vectorisation}{52}{subsection.152}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}Cholesky Update and Downdate}{52}{subsection.153}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.3}Caching learned GPs for fast prediction}{52}{subsection.154}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.4}Parallelisation of GP learning and hyper-parameter batching}{52}{subsection.155}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.5}Parallelisation of GP prediction and relevant subtleties}{52}{subsection.156}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.6}Fast vectorised GP drawing for regression and classification}{52}{subsection.157}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Spatial Complexity}{52}{section.158}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Symmetry of AVA multiclass classifier}{52}{subsection.159}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.2}Creating predictor objects to modularise prediction}{52}{subsection.160}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Time \& Spatial Complexity}{52}{section.161}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.1}Avoiding full covariance computations}{52}{subsection.162}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.2}Taking advantage of diagonal log-likelihood Hessians}{52}{subsection.163}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Other Approximations for Gaussian Process Classification}{53}{appendix.164}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Appendix:OtherApproximationsGaussianProcessClassification}{{B}{53}{Other Approximations for Gaussian Process Classification}{appendix.164}{}}
\newlabel{Appendix:OtherApproximationsGaussianProcessClassification@cref}{{[appendix][2][2147483647]B}{53}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Expectation Propagation}{53}{section.165}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Variational Inference}{53}{section.166}}
\@writefile{toc}{\vspace  {2em}}
\bibdata{Bibliography}
\bibcite{AsherBender}{{1}{2013}{{Bender et~al.}}{{}}}
\bibcite{ParametricPOMDP}{{2}{2006}{{Brooks et~al.}}{{}}}
\bibcite{Colbo201441}{{3}{2014}{{Colbo et~al.}}{{}}}
\bibcite{StefanWilliams:Rugosity}{{4}{2012}{{Friedman et~al.}}{{}}}
\bibcite{Squidle}{{5}{2015}{{Friedman et~al.}}{{}}}
\bibcite{CentralDifferenceTable}{{6}{2010}{{Holoborodko}}{{}}}
\bibcite{IMOS}{{7}{2009}{{IMOS}}{{}}}
\bibcite{Kapoor}{{8}{2010}{{Kapoor et~al.}}{{}}}
\bibcite{Krause:2008:NSP:1390681.1390689}{{9}{2008}{{Krause et~al.}}{{}}}
\bibcite{AdaptiveNonStationaryKernel}{{10}{2007}{{Lang et~al.}}{{}}}
\bibcite{Roman:SequentialBayesianOptimisation}{{11}{2014}{{Marchant et~al.}}{{}}}
\bibcite{Niedzielski2013231}{{12}{2013}{{Niedzielski et~al.}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{55}{dummy.167}}
\newlabel{Bibliography}{{6}{55}{Variational Inference}{dummy.167}{}}
\newlabel{Bibliography@cref}{{[dummy][6][2147483647]6}{55}}
\bibcite{NOAA}{{13}{2014}{{NOAA}}{{}}}
\bibcite{GaussianProcessForMachineLearning}{{14}{2006}{{Rasmussen and Williams}}{{}}}
\bibcite{Rigby:ROB20372}{{15}{2010}{{Rigby et~al.}}{{}}}
\bibcite{ShannonEntropy}{{16}{1948}{{Shannon}}{{}}}
\bibcite{Steinberg2015128}{{17}{2015}{{Steinberg et~al.}}{{}}}
\bibcite{GaussianProcessTerrainFigure}{{18}{2013}{{Tong}}{{}}}
