# OceanTerrainExploration
Active Path Planning of Autonomous Underwater Vehicles for Ocean Terrain Exploration

	Thanks to depth sounding, acoustic, and optical technology, we now have access to detailed information regarding ocean terrain structures across many parts of the globe. These information come mainly in the form of \textit{Bathymetric} data, which records the measured ocean terrain depth, slope, rugosity and such terrain information at various pairs of latitude and longitude locations of the globe. Currently, bathymetric data has been recorded with advanced techniques such as SONAR (\textbf{SO}und \textbf{N}avigation \textbf{A}nd \textbf{R}anging), LIDAR (\textbf{LI}ght \textbf{D}etection \textbf{A}nd \textbf{R}anging), and Multibeam Echosounder for more than half a century. With such volume of bathymetric information, we can reconstruct accurate 3D models for the ocean terrain structure through spatial analytics and modeling techniques.\\
	
	However, bathymetric data is only able to tell us the spatial structure of the marine terrain. It does not indicate what each part of the ocean floor is composed of. For instance, bathymetric data do not include information about what type of marine habitats reside in the various parts of the ocean floor, nor does it contain clues about what minerals or natural resources may be present. With the recent trend in big data analysis, there has been an increase in scientific and economical demands - from ecologist and geologists to resource and mining industries - for the ability to predict or infer the types of marine habitats or natural resources residing at various marine environments.\\
	
	This implies that we would need to map the ocean floor again, but with other sensing equipments - mainly vision based - in order to image the types of habitats, resources, or other interesting properties of different parts of the ocean floor. Unfortunately, unlike bathymetric data, which can often be measured with decent accuracy at a distance (for example, with SONAR from ships at sea level), such visual image information can only be obtained through expensive missions with Autonomous Underwater Vehicles (AUVs) that travel deep into the ocean to image underwater environments at a close distance.\\
	
	As a result, we currently have a lack of \textit{label} data, which is a summary (or \textit{label}) of the habitats, resources, and other interesting properties observed at various parts of the ocean, as compared to the more plentiful bathymetric (depth) data. Due to the difficult limitations in cost and time, it is infeasible to traverse through enough of the ocean floor to ever obtain enough label data like how bathymetric data was gathered.\\
	
	This project will investigate machine learning methods for Autonomous Underwater Vehicles (AUVs) to intelligently and actively select an optimal underwater path to take for underwater imaging - in order to maximise information, or entropy, gained throughout that path in a given underwater region, while constrained by cost or time. Intuitively, this information gathering technique (also sometimes referred to as \textit{active sampling}) surrounds the idea that observations in one part of the ocean modifies uncertainties about other parts of the ocean. The hope is that, with a well designed path planner, the final trajectory can maximise information gained about the habitats and resources residing in a large part of the ocean.\\
	
Author: Kelvin Hsu
